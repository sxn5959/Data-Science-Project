{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d0a9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cc5113",
   "metadata": {},
   "outputs": [],
   "source": [
    "og_data=pd.read_csv(r'./Dataset/RTADataset.csv') #data file in same folder as project code\n",
    "og_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11e202e",
   "metadata": {},
   "outputs": [],
   "source": [
    "og_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034289ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['Age_band_of_driver'].unique().tolist()\n",
    "data['Vehicle_driver_relation'].unique().tolist()\n",
    "data['Driving_experience'].unique().tolist()\n",
    "data['Types_of_Junction'].unique().tolist()\n",
    "data['Road_surface_type'].unique().tolist()\n",
    "data['Light_conditions'].unique().tolist()\n",
    "data['Weather_conditions'].unique().tolist()\n",
    "data['Type_of_collision'].unique().tolist()\n",
    "data['Vehicle_movement'].unique().tolist()\n",
    "data['Cause_of_accident'].unique().tolist()\n",
    "data['Accident_severity'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1abc47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the dataset\n",
    "\n",
    "#deep copy of data\n",
    "data = og_data.copy()\n",
    "\n",
    "# maintaining the only required columns in the data set\n",
    "data = data.loc[:, ['Age_band_of_driver', \n",
    "                    'Vehicle_driver_relation', \n",
    "                    'Driving_experience', \n",
    "                    'Types_of_Junction', \n",
    "                    'Road_surface_type', \n",
    "                    'Light_conditions', \n",
    "                    'Weather_conditions', \n",
    "                    'Type_of_collision', \n",
    "                    'Vehicle_movement', \n",
    "                    'Cause_of_accident', \n",
    "                    'Accident_severity']]\n",
    "\n",
    "print(data.info())\n",
    "\n",
    "# storing the updated dataframe into the new CSV file\n",
    "data.to_csv(r'../Dataset/CleanedDataset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99265ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting categorical features to numeric\n",
    "for column in data:\n",
    "    print(column,': ', data[column].unique().tolist())\n",
    "    \n",
    "# replacing the value for accident severity\n",
    "#data['Accident_severity'] = data['Accident_severity'].replace({'Slight Injury': 1, 'Serious Injury' : 2})\n",
    "#data\n",
    "\n",
    "\n",
    "data.Accident_severity = data.Accident_severity.map({'Slight Injury':0, 'Serious Injury':1, 'Fatal Injury': 2})\n",
    "\n",
    "#check if unknown needs to be dropped?\n",
    "filtered_data = data.dropna()\n",
    "\n",
    "#need to map all the variables\n",
    "#mapping variables that are sequentially up\n",
    "#need to think on how to map variables that are not sequential\n",
    "#drop nan?\n",
    "#what to do with unknown?\n",
    "data.Age_band_of_driver = data.Age_band_of_driver.map({'Under 18':0, '18-30':1, '31-50': 2, 'Over 51': 3, 'Unknown': 4}) \n",
    "\n",
    "data.Driving_experience = data.Driving_experience.map({'No Licence': 0, 'Below 1yr': 1, '1-2yr': 2 , '2-5yr': 3, '5-10yr': 4, 'Above 10yr': 5, 'unknown': 6})\n",
    "data.Road_surface_type = data.Road_surface_type.map({'Earth roads': 0 , 'Gravel roads': 1, 'Asphalt roads with some distress': 2, 'Asphalt roads': 3, 'Other': 4})\n",
    "data.Light_conditions = data.Light_conditions.map({'Daylight': 0, 'Darkness - lights lit': 1, 'Darkness - lights unlit': 2, 'Darkness - no lighting': 3})\n",
    "\n",
    "\n",
    "#data.Vehicle_driver_relation = data.Vehicle_driver_relation.map#({'Employee', 'Unknown', 'Owner', nan, 'Other'})\n",
    "#data.Types_of_Junction = data.Types_of_Junction.map# :  ['No junction', 'Y Shape', 'Crossing', 'O Shape', 'Other', 'Unknown', 'T Shape', 'X Shape', nan]\n",
    "#Weather_conditions :  ['Normal', 'Raining', 'Raining and Windy', 'Cloudy', 'Other', 'Windy', 'Snow', 'Unknown', 'Fog or mist']\n",
    "#Type_of_collision :  ['Collision with roadside-parked vehicles', 'Vehicle with vehicle collision', 'Collision with roadside objects', 'Collision with animals', 'Other', 'Rollover', 'Fall from vehicles', 'Collision with pedestrians', 'With Train', 'Unknown', nan]\n",
    "#Vehicle_movement :  ['Going straight', 'U-Turn', 'Moving Backward', 'Turnover', 'Waiting to go', 'Getting off', 'Reversing', 'Unknown', 'Parked', 'Stopping', 'Overtaking', 'Other', 'Entering a junction', nan]\n",
    "#Cause_of_accident :  ['Moving Backward', 'Overtaking', 'Changing lane to the left', 'Changing lane to the right', 'Overloading', 'Other', 'No priority to vehicle', 'No priority to pedestrian', 'No distancing', 'Getting off the vehicle improperly', 'Improper parking', 'Overspeed', 'Driving carelessly', 'Driving at high speed', 'Driving to the left', 'Unknown', 'Overturning', 'Turnover', 'Driving under the influence of drugs', 'Drunk driving']\n",
    "#Accident_severity :  ['Slight Injury', 'Serious Injury', 'Fatal injury']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d21c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##splitting data into training set and test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.drop(['Accident_severity'], axis = 1)\n",
    "y = data.Accident_severity\n",
    "\n",
    "#cross validation variable\n",
    "cv_num = 5\n",
    "\n",
    "#random state\n",
    "r_state=1\n",
    "\n",
    "#80/20 test train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.8, random_state = r_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1205cdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Tree Model\n",
    "\n",
    "#gradient boosting on training set with 500 trees\n",
    "#effect of learning rates\n",
    "#boosted_hitters = GradientBoostingRegressor(n_estimators = 500,learning_rate = 0.01, max_depth = 4, random_state = 4123)\n",
    "#boosted_hitters.fit(X_train, y_train)\n",
    "\n",
    "#function to vary learning rates; depth undefined\n",
    "def variable_learn_boosting(X_train, X_test, y_train, y_test, varlearn):\n",
    "    train_MSE = {}\n",
    "    test_MSE = {}\n",
    "    for i in varlearn:\n",
    "        #classifier with rng state 4/1/23 with 500 trees and variable learning rate based on passed values\n",
    "        clf = GradientBoostingRegressor(n_estimators=500, learning_rate=i, random_state=random_state)\n",
    "        clf.fit(X_train, y_train)\n",
    "        p = clf.predict(X_train)\n",
    "        train_MSE[i] = mean_squared_error(p, y_train)\n",
    "        p = clf.predict(X_test)\n",
    "        test_MSE[i] = mean_squared_error(p, y_test)\n",
    "    return (train_MSE, test_MSE)\n",
    "\n",
    "###\n",
    "\n",
    "results = variable_learn_boosting(X_train, X_test, y_train.values.ravel(), y_test.values.ravel(), np.linspace(0.01, 1, 100))\n",
    "\n",
    "lists = sorted(results[0].items())\n",
    "x, y = zip(*lists)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(x, y, color='blue')\n",
    "plt.xlabel('Learning Rates')\n",
    "plt.ylabel('Corresponding Training MSE')\n",
    "plt.title('MSE vs Learning Rate')\n",
    "plt.grid()\n",
    "\n",
    "###\n",
    "\n",
    "parameters = {'learning_rate': np.linspace(0.01, 1, 100)}\n",
    "clf = GridSearchCV(ensemble.GradientBoostingRegressor(random_state= r_state), parameters, cv= cv_num)\n",
    "clf.fit(X= X_train, y = y_train.values.ravel())\n",
    "tree_model = clf.best_estimator_\n",
    "print (round(clf.best_score_,3), clf.best_params_)\n",
    "p = tree_model.predict(X_test)\n",
    "print(\"Test MSE is: \" + str(round(mean_squared_error(p, y_test),3)))\n",
    "\n",
    "###\n",
    "\n",
    "feature_importances = tree_model.feature_importances_\n",
    "feature_importances.sort()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.barh(X_train.columns.tolist(), feature_importances)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importances')\n",
    "plt.title(\"Importance of Features\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95402739",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn import tree\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor, GradientBoostingRegressor, BaggingRegressor\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "### Decision Tree\n",
    "\n",
    "#parameters = {'max_depth':(2,4,6,8,10)}\n",
    "parameters = {'max_depth': range(1,10)}\n",
    "mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "#return_train_score=True allows for train score to be tracked later on if needed\n",
    "clf = GridSearchCV(tree.DecisionTreeRegressor(random_state=r_state), parameters, cv=cv_num, scoring=mse_scorer, return_train_score=True)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "tree_model = clf.best_estimator_\n",
    "print('Optimal value of '+ str(clf.best_params_))\n",
    "\n",
    "p = tree_model.predict(X_train)\n",
    "print(\"Training MSE is: \" + str(mean_squared_error(p, y_train)))\n",
    "\n",
    "p = tree_model.predict(X_test)\n",
    "print(\"Testing MSE is: \" + str(mean_squared_error(p, y_test)))\n",
    "###\n",
    "\n",
    "\n",
    "# Set size for the plot\n",
    "plt.figure(figsize=(150,10))\n",
    "# Plot the tree (use filled for more clarity)\n",
    "plot_tree(tree_model, filled = True, fontsize=8)\n",
    "\n",
    "plt.show() # Display the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e021cbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Bagging\n",
    "#bagging = BaggingRegressor(random_state=r_state)\n",
    "#bagging.fit(X=X_train, y=y_train.values.ravel())\n",
    "#p = bagging.predict(X_test)\n",
    "#print(\"Test MSE is: \" + str(mean_squared_error(p, y_test)))\n",
    "\n",
    "parameters = {'n_estimators': np.arange(1, 10, 1)}\n",
    "#cross validation with parameters and 5-folds\n",
    "clf = GridSearchCV(ensemble.BaggingRegressor(random_state=r_state), parameters, cv=cv_num)\n",
    "clf.fit(X_train, y_train.values.ravel())\n",
    "bagged_tree_model = clf.best_estimator_\n",
    "print (\"Optimale values: \", clf.best_params_)\n",
    "\n",
    "p = bagged_tree_model.predict(X_train)\n",
    "print(\"Training MSE is: \" + str(round(mean_squared_error(p, y_train),4)))\n",
    "\n",
    "p = bagged_tree_model.predict(X_test)\n",
    "print(\"Testing MSE is: \" + str(round(mean_squared_error(p, y_test),4)))\n",
    "\n",
    "feature_importances = np.mean([tree.feature_importances_ for tree in bagged_tree_model.estimators_], axis=0)\n",
    "feature_importances.sort()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.barh(X_train.columns.tolist(), feature_importances)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importances')\n",
    "plt.title(\"Importance of Features\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694f9fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Random Forests\n",
    "parameters = {'max_depth': range(1,10), 'n_estimators': np.arange(1, 10, 1)}\n",
    "#cross validation with parameters and 5-folds\n",
    "clf = GridSearchCV(ensemble.RandomForestRegressor(random_state=r_state), parameters, cv=cv_num)\n",
    "clf.fit(X_train, y_train.values.ravel())\n",
    "forest_model = clf.best_estimator_\n",
    "print (\"Optimale values: \", clf.best_params_)\n",
    "\n",
    "p = forest_model.predict(X_train)\n",
    "print(\"Training MSE is: \" + str(round(mean_squared_error(p, y_train),4)))\n",
    "\n",
    "p = forest_model.predict(X_test)\n",
    "print(\"Testing MSE is: \" + str(round(mean_squared_error(p, y_test),4)))\n",
    "\n",
    "\n",
    "feature_importances = np.mean([tree.feature_importances_ for tree in forest_model.estimators_], axis=0)\n",
    "feature_importances.sort()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.barh(X_train.columns.tolist(), feature_importances)\n",
    "plt.xlabel('Features')\n",
    "plt.ylabel('Importances')\n",
    "plt.title(\"Importance of Features\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
